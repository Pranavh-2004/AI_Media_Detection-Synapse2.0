{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranavh-2004/AI_Media_Detection-Synapse2.0/blob/main/Working_Product.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import os\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "zipref=zipfile.ZipFile(\"10_food_classes_all_data.zip\")\n",
        "zipref.extractall()\n",
        "zipref.close()\n",
        "!pip install imagehash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyV12nYsGJdK",
        "outputId": "be30eb9e-70ef-4422-b196-5704751e898e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-20 05:12:33--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.124.207, 142.250.152.207, 142.250.128.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.124.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 519183241 (495M) [application/zip]\n",
            "Saving to: ‘10_food_classes_all_data.zip.2’\n",
            "\n",
            "10_food_classes_all 100%[===================>] 495.13M  70.3MB/s    in 7.6s    \n",
            "\n",
            "2024-04-20 05:12:41 (64.9 MB/s) - ‘10_food_classes_all_data.zip.2’ saved [519183241/519183241]\n",
            "\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define ImageDataGenerators for training and testing\n",
        "\n",
        "train_datagen_augmented = ImageDataGenerator(\n",
        "    rotation_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    height_shift_range=0.2,\n",
        "    width_shift_range=0.2\n",
        "\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    #rescale=1./255\n",
        "\n",
        ")\n",
        "train_datagen = ImageDataGenerator(\n",
        "    #rescale=1./255\n",
        "\n",
        ")\n",
        "\n",
        "# Flow training images in batches using the generator\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(\n",
        "    '10_food_classes_all_data/train/',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    seed=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Flow validation images in batches using the generator\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    '10_food_classes_all_data/test/',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    seed=42\n",
        ")\n",
        "train_data=train_datagen.flow_from_directory(\n",
        "    '10_food_classes_all_data/train/',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    seed=42,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEOBFDDmGWxY",
        "outputId": "8ae971a6-d0dc-4b1d-b457-56d043b684e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7500 images belonging to 10 classes.\n",
            "Found 2500 images belonging to 10 classes.\n",
            "Found 7500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "base_model=tf.keras.applications.EfficientNetB4(include_top=False)\n",
        "base_model.trainable=False #we are taking pre trained model so we shouldnt train it and disturb its accuracy\n",
        "\n",
        "inputs=tf.keras.layers.Input(shape=(128,128,3))\n",
        "x=base_model(inputs)\n",
        "x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs=tf.keras.layers.Dense(10,activation='softmax')(x)\n",
        "model=tf.keras.models.Model(inputs,outputs)\n",
        "model.summary()\n",
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "               optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "               metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAuUfYpTGIYJ",
        "outputId": "7c8cbfd8-83dd-4a01-e7f5-93dad4af1e6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb4 (Functional  (None, None, None, 1792   17673823  \n",
            " )                           )                                   \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 1792)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                17930     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17691753 (67.49 MB)\n",
            "Trainable params: 17930 (70.04 KB)\n",
            "Non-trainable params: 17673823 (67.42 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data_augmented,epochs=3,validation_data=test_data,steps_per_epoch=len(train_data),validation_steps=int(0.2*len(test_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIobr5UOH9em",
        "outputId": "9d42dd8a-9e6a-46e4-831b-e7213e8d5352"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "235/235 [==============================] - 628s 3s/step - loss: 1.2658 - accuracy: 0.5995 - val_loss: 0.7093 - val_accuracy: 0.7688\n",
            "Epoch 2/3\n",
            "235/235 [==============================] - 597s 3s/step - loss: 0.9416 - accuracy: 0.6967 - val_loss: 0.6451 - val_accuracy: 0.8042\n",
            "Epoch 3/3\n",
            "235/235 [==============================] - 582s 2s/step - loss: 0.8699 - accuracy: 0.7135 - val_loss: 0.6133 - val_accuracy: 0.8062\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fb0cd0f3e50>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable=True\n",
        "for i,layer in enumerate(base_model.layers[:-10]):\n",
        "  layer.trainable=False"
      ],
      "metadata": {
        "id": "eoce1KJCGgxq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "               optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),#new learning rate after changing layers=old learning rate/10\n",
        "               metrics=['accuracy'])\n",
        "model.fit(train_data_augmented,epochs=6,validation_data=test_data,steps_per_epoch=len(train_data),validation_steps=int(0.2*len(test_data)),initial_epoch=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SblfVEe1GkbJ",
        "outputId": "022f17d0-86d2-476c-8247-1ab96373fe93"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/6\n",
            "235/235 [==============================] - 654s 3s/step - loss: 0.8686 - accuracy: 0.7116 - val_loss: 0.6204 - val_accuracy: 0.7875\n",
            "Epoch 5/6\n",
            "235/235 [==============================] - 611s 3s/step - loss: 0.7839 - accuracy: 0.7437 - val_loss: 0.5508 - val_accuracy: 0.8125\n",
            "Epoch 6/6\n",
            "235/235 [==============================] - 612s 3s/step - loss: 0.7072 - accuracy: 0.7668 - val_loss: 0.4781 - val_accuracy: 0.8167\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fb0c071b550>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference on sample images from the training data\n",
        "images, labels = next(train_data)  # Get one batch for inference\n",
        "predictions = model.predict(images)\n",
        "\n",
        "# Convert predictions to desired format\n",
        "object_positions_list = []\n",
        "for pred in predictions:\n",
        "    object_positions = []\n",
        "    for i in range(0, len(pred), 4):  # Assuming each object has 4 coordinates (a, b, c, d)\n",
        "        if i + 4 <= len(pred):  # Check if there are enough values for unpacking\n",
        "            a, b, c, d = pred[i:i+4]\n",
        "            object_positions.append({'x': [[a, b], [c, d]]})\n",
        "        else:\n",
        "            break\n",
        "    object_positions_list.append({'objects': object_positions})\n",
        "\n",
        "print(object_positions_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c68JR6jgIGnG",
        "outputId": "480c757d-f809-4edd-be21-7fd93c973867"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n",
            "[{'objects': [{'x': [[0.1914132, 0.56806844], [0.01987432, 0.06664723]]}, {'x': [[0.002473449, 0.00081576436], [0.113705255, 0.029870503]]}]}, {'objects': [{'x': [[0.06651431, 0.078465216], [0.32503846, 0.01978449]]}, {'x': [[0.0012009578, 0.0017722325], [0.0073262937, 0.14076643]]}]}, {'objects': [{'x': [[0.015676245, 0.0013215535], [0.9181736, 0.007259379]]}, {'x': [[0.0045528742, 0.00029989926], [0.0038643705, 0.0064367764]]}]}, {'objects': [{'x': [[0.00026248273, 0.0021917704], [0.0014579231, 0.002119934]]}, {'x': [[0.003878405, 0.007929086], [0.001305932, 0.0004167375]]}]}, {'objects': [{'x': [[0.0017771195, 0.0029942212], [0.0058182576, 0.01611626]]}, {'x': [[0.011431759, 0.003601527], [0.016552014, 0.0005920256]]}]}, {'objects': [{'x': [[0.0034851483, 0.00042670438], [0.0023543178, 0.009210413]]}, {'x': [[0.95156664, 0.00024417482], [3.6481848e-05, 0.020524535]]}]}, {'objects': [{'x': [[0.006710948, 0.0014575939], [0.0028148517, 0.0043336763]]}, {'x': [[0.0013809312, 0.003034195], [0.0032007548, 0.00013934525]]}]}, {'objects': [{'x': [[0.016039735, 0.8520662], [0.014945943, 0.015620837]]}, {'x': [[0.023180155, 4.677789e-05], [0.0011592603, 0.011136761]]}]}, {'objects': [{'x': [[0.024424363, 0.010135124], [0.028529841, 0.049893226]]}, {'x': [[0.025721272, 0.00047188677], [0.8109252, 0.007615834]]}]}, {'objects': [{'x': [[0.18228002, 0.20066585], [0.03960442, 0.004781554]]}, {'x': [[0.012056873, 0.061212502], [0.03335049, 0.24133542]]}]}, {'objects': [{'x': [[0.006132645, 0.0048478507], [0.03487522, 0.020471878]]}, {'x': [[0.01595488, 0.5142799], [0.0630601, 0.15269852]]}]}, {'objects': [{'x': [[0.06902967, 0.0045375186], [0.0011088686, 0.0017229903]]}, {'x': [[0.004797104, 0.00058246724], [0.008991929, 0.8851653]]}]}, {'objects': [{'x': [[0.022875873, 0.0074789263], [0.00199855, 0.18529917]]}, {'x': [[0.00034088013, 0.00047809145], [0.00032562859, 0.017165713]]}]}, {'objects': [{'x': [[0.03711457, 0.0014267942], [0.86997426, 0.010264374]]}, {'x': [[0.0001663049, 0.00013103486], [0.07714203, 0.000571257]]}]}, {'objects': [{'x': [[0.89834195, 0.011720756], [0.00014414616, 0.0112113515]]}, {'x': [[0.038038317, 0.029047173], [0.0014191917, 0.006105824]]}]}, {'objects': [{'x': [[0.99439424, 0.0019168354], [0.0008852679, 1.9334304e-05]]}, {'x': [[4.9800046e-06, 6.583635e-05], [0.000721282, 0.0014397341]]}]}, {'objects': [{'x': [[0.00017099397, 1.7858672e-05], [0.00032617798, 3.9149178e-05]]}, {'x': [[7.085627e-05, 0.00011691487], [0.9989612, 0.00013185557]]}]}, {'objects': [{'x': [[0.0010822098, 0.9539554], [0.0001481898, 0.024652543]]}, {'x': [[0.0020574243, 2.2416027e-05], [0.0001381813, 5.3523754e-06]]}]}, {'objects': [{'x': [[6.343836e-05, 0.00025336654], [0.00093521806, 0.0007725821]]}, {'x': [[0.0031710637, 0.9802764], [0.010292998, 0.00035029548]]}]}, {'objects': [{'x': [[0.17820595, 0.038925022], [0.040819936, 0.13320795]]}, {'x': [[0.043591514, 0.050039776], [0.47997394, 0.001984702]]}]}, {'objects': [{'x': [[0.00031108578, 6.986642e-05], [0.0011535462, 0.00041327983]]}, {'x': [[0.9971026, 0.0005479602], [0.000106067855, 0.00013400755]]}]}, {'objects': [{'x': [[0.0011367038, 0.0026968783], [0.0025748545, 0.00023236929]]}, {'x': [[0.00072430976, 0.050197035], [0.0070174537, 0.00039448545]]}]}, {'objects': [{'x': [[0.0008433227, 0.00096000347], [0.00010737747, 0.94882005]]}, {'x': [[0.0023578973, 4.6828454e-06], [0.000323705, 0.0028968647]]}]}, {'objects': [{'x': [[3.5060166e-05, 6.231427e-05], [0.00015145061, 0.0001143545]]}, {'x': [[9.4104034e-05, 0.9991257], [8.2563776e-05, 0.00013449731]]}]}, {'objects': [{'x': [[0.07802166, 0.0043090764], [0.08780076, 0.08357542]]}, {'x': [[0.023335332, 0.00022253508], [0.5829252, 0.07426117]]}]}, {'objects': [{'x': [[0.5923288, 0.0018295766], [0.24348474, 0.006139411]]}, {'x': [[0.00028547522, 9.2379676e-05], [0.017393695, 0.13663979]]}]}, {'objects': [{'x': [[0.00086279295, 1.35317605e-05], [0.000937164, 0.00011571145]]}, {'x': [[0.00011473895, 0.99754745], [8.061807e-05, 0.00016478756]]}]}, {'objects': [{'x': [[0.00810808, 0.011820938], [0.018476384, 0.017316652]]}, {'x': [[0.012073018, 0.02866592], [0.1786845, 0.0036770054]]}]}, {'objects': [{'x': [[0.00018231462, 0.004076473], [5.4190034e-05, 0.0035049785]]}, {'x': [[0.038598746, 0.0002995772], [0.0001169341, 0.0010809558]]}]}, {'objects': [{'x': [[6.1710525e-05, 0.008760745], [2.2507653e-05, 0.011941801]]}, {'x': [[0.97606224, 0.0002108238], [0.00014442718, 2.5415377e-05]]}]}, {'objects': [{'x': [[0.0022573466, 0.0028203586], [0.0010288985, 0.016686128]]}, {'x': [[0.86477923, 0.0034381435], [0.009419566, 0.008643096]]}]}, {'objects': [{'x': [[0.017213995, 0.002100105], [0.0018967421, 0.00093349523]]}, {'x': [[0.00041720908, 0.0017323347], [0.0012486514, 0.9723432]]}]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import sys\n",
        "\n",
        "import numpy\n",
        "from PIL import Image, ImageFilter\n",
        "try:\n",
        "\tANTIALIAS = Image.Resampling.LANCZOS\n",
        "except AttributeError:\n",
        "\t# deprecated in pillow 10\n",
        "\t# https://pillow.readthedocs.io/en/stable/deprecations.html\n",
        "\tANTIALIAS = Image.ANTIALIAS\n",
        "\n",
        "__version__ = '4.3.1'\n",
        "\n",
        "\"\"\"\n",
        "You may copy this file, if you keep the copyright information below:\n",
        "\n",
        "\n",
        "Copyright (c) 2013-2022, Johannes Buchner\n",
        "https://github.com/JohannesBuchner/imagehash\n",
        "\n",
        "All rights reserved.\n",
        "\n",
        "Redistribution and use in source and binary forms, with or without\n",
        "modification, are permitted provided that the following conditions are\n",
        "met:\n",
        "\n",
        "Redistributions of source code must retain the above copyright\n",
        "notice, this list of conditions and the following disclaimer.\n",
        "\n",
        "Redistributions in binary form must reproduce the above copyright\n",
        "notice, this list of conditions and the following disclaimer in the\n",
        "documentation and/or other materials provided with the distribution.\n",
        "\n",
        "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\n",
        "IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n",
        "TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n",
        "PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n",
        "HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n",
        "SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n",
        "LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n",
        "DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n",
        "THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
        "(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
        "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def _binary_array_to_hex(arr):\n",
        "\t\"\"\"\n",
        "\tinternal function to make a hex string out of a binary array.\n",
        "\t\"\"\"\n",
        "\tbit_string = ''.join(str(b) for b in 1 * arr.flatten())\n",
        "\twidth = int(numpy.ceil(len(bit_string) / 4))\n",
        "\treturn '{:0>{width}x}'.format(int(bit_string, 2), width=width)\n",
        "\n",
        "\n",
        "class ImageHash:\n",
        "\t\"\"\"\n",
        "\tHash encapsulation. Can be used for dictionary keys and comparisons.\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(self, binary_array):\n",
        "\t\t# type: (NDArray) -> None\n",
        "\t\tself.hash = binary_array  # type: NDArray\n",
        "\n",
        "\tdef __str__(self):\n",
        "\t\treturn _binary_array_to_hex(self.hash.flatten())\n",
        "\n",
        "\tdef __repr__(self):\n",
        "\t\treturn repr(self.hash)\n",
        "\n",
        "\tdef __sub__(self, other):\n",
        "\t\t# type: (ImageHash) -> int\n",
        "\t\tif other is None:\n",
        "\t\t\traise TypeError('Other hash must not be None.')\n",
        "\t\tif self.hash.size != other.hash.size:\n",
        "\t\t\traise TypeError('ImageHashes must be of the same shape.', self.hash.shape, other.hash.shape)\n",
        "\t\treturn numpy.count_nonzero(self.hash.flatten() != other.hash.flatten())\n",
        "\n",
        "\tdef __eq__(self, other):\n",
        "\t\t# type: (object) -> bool\n",
        "\t\tif other is None:\n",
        "\t\t\treturn False\n",
        "\t\treturn numpy.array_equal(self.hash.flatten(), other.hash.flatten())  # type: ignore\n",
        "\n",
        "\tdef __ne__(self, other):\n",
        "\t\t# type: (object) -> bool\n",
        "\t\tif other is None:\n",
        "\t\t\treturn False\n",
        "\t\treturn not numpy.array_equal(self.hash.flatten(), other.hash.flatten())  # type: ignore\n",
        "\n",
        "\tdef __hash__(self):\n",
        "\t\t# this returns a 8 bit integer, intentionally shortening the information\n",
        "\t\treturn sum([2**(i % 8) for i, v in enumerate(self.hash.flatten()) if v])\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\t# Returns the bit length of the hash\n",
        "\t\treturn self.hash.size\n",
        "\n",
        "\n",
        "# dynamic code for typing\n",
        "try:\n",
        "\t# specify allowed values if possible (py3.8+)\n",
        "\tfrom typing import Literal\n",
        "\tWhashMode = Literal['haar', 'db4']  # type: ignore\n",
        "except ImportError:\n",
        "\tWhashMode = str  # type: ignore\n",
        "\n",
        "try:\n",
        "\t# enable numpy array typing (py3.7+)\n",
        "\timport numpy.typing\n",
        "\tNDArray = numpy.typing.NDArray[numpy.bool_]\n",
        "except (AttributeError, ImportError):\n",
        "\tNDArray = list  # type: ignore\n",
        "\n",
        "# type of Callable\n",
        "if sys.version_info >= (3, 3):\n",
        "\tif sys.version_info >= (3, 9, 0) and sys.version_info <= (3, 9, 1):\n",
        "\t\t# https://stackoverflow.com/questions/65858528/is-collections-abc-callable-bugged-in-python-3-9-1\n",
        "\t\tfrom typing import Callable\n",
        "\telse:\n",
        "\t\tfrom collections.abc import Callable\n",
        "\ttry:\n",
        "\t\tMeanFunc = Callable[[NDArray], float]\n",
        "\t\tHashFunc = Callable[[Image.Image], ImageHash]\n",
        "\texcept TypeError:\n",
        "\t\tMeanFunc = Callable  # type: ignore\n",
        "\t\tHashFunc = Callable  # type: ignore\n",
        "# end of dynamic code for typing\n",
        "\n",
        "\n",
        "def hex_to_hash(hexstr):\n",
        "\t# type: (str) -> ImageHash\n",
        "\t\"\"\"\n",
        "\tConvert a stored hash (hex, as retrieved from str(Imagehash))\n",
        "\tback to a Imagehash object.\n",
        "\n",
        "\tNotes:\n",
        "\t1. This algorithm assumes all hashes are either\n",
        "\t\t\tbidimensional arrays with dimensions hash_size * hash_size,\n",
        "\t\t\tor onedimensional arrays with dimensions binbits * 14.\n",
        "\t2. This algorithm does not work for hash_size < 2.\n",
        "\t\"\"\"\n",
        "\thash_size = int(numpy.sqrt(len(hexstr) * 4))\n",
        "\t# assert hash_size == numpy.sqrt(len(hexstr)*4)\n",
        "\tbinary_array = '{:0>{width}b}'.format(int(hexstr, 16), width=hash_size * hash_size)\n",
        "\tbit_rows = [binary_array[i:i + hash_size] for i in range(0, len(binary_array), hash_size)]\n",
        "\thash_array = numpy.array([[bool(int(d)) for d in row] for row in bit_rows])\n",
        "\treturn ImageHash(hash_array)\n",
        "\n",
        "\n",
        "def hex_to_flathash(hexstr, hashsize):\n",
        "\t# type: (str, int) -> ImageHash\n",
        "\thash_size = int(len(hexstr) * 4 / (hashsize))\n",
        "\tbinary_array = '{:0>{width}b}'.format(int(hexstr, 16), width=hash_size * hashsize)\n",
        "\thash_array = numpy.array([[bool(int(d)) for d in binary_array]])[-hash_size * hashsize:]\n",
        "\treturn ImageHash(hash_array)\n",
        "\n",
        "\n",
        "def hex_to_multihash(hexstr):\n",
        "\t# type: (str) -> ImageMultiHash\n",
        "\t\"\"\"\n",
        "\tConvert a stored multihash (hex, as retrieved from str(ImageMultiHash))\n",
        "\tback to an ImageMultiHash object.\n",
        "\n",
        "\tThis function is based on hex_to_hash so the same caveats apply. Namely:\n",
        "\n",
        "\t1. This algorithm assumes all hashes are either\n",
        "\t\t\tbidimensional arrays with dimensions hash_size * hash_size,\n",
        "\t\t\tor onedimensional arrays with dimensions binbits * 14.\n",
        "\t2. This algorithm does not work for hash_size < 2.\n",
        "\t\"\"\"\n",
        "\tsplit = hexstr.split(',')\n",
        "\thashes = [hex_to_hash(x) for x in split]\n",
        "\treturn ImageMultiHash(hashes)\n",
        "\n",
        "\n",
        "def old_hex_to_hash(hexstr, hash_size=8):\n",
        "\t# type: (str, int) -> ImageHash\n",
        "\t\"\"\"\n",
        "\tConvert a stored hash (hex, as retrieved from str(Imagehash))\n",
        "\tback to a Imagehash object. This method should be used for\n",
        "\thashes generated by ImageHash up to version 3.7. For hashes\n",
        "\tgenerated by newer versions of ImageHash, hex_to_hash should\n",
        "\tbe used instead.\n",
        "\t\"\"\"\n",
        "\tarr = []\n",
        "\tcount = hash_size * (hash_size // 4)\n",
        "\tif len(hexstr) != count:\n",
        "\t\temsg = 'Expected hex string size of {}.'\n",
        "\t\traise ValueError(emsg.format(count))\n",
        "\tfor i in range(count // 2):\n",
        "\t\th = hexstr[i * 2:i * 2 + 2]\n",
        "\t\tv = int('0x' + h, 16)\n",
        "\t\tarr.append([v & 2**i > 0 for i in range(8)])\n",
        "\treturn ImageHash(numpy.array(arr))\n",
        "\n",
        "\n",
        "def average_hash(image, hash_size=8, mean=numpy.mean):\n",
        "\t# type: (Image.Image, int, MeanFunc) -> ImageHash\n",
        "\t\"\"\"\n",
        "\tAverage Hash computation\n",
        "\n",
        "\tImplementation follows https://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html\n",
        "\n",
        "\tStep by step explanation: https://web.archive.org/web/20171112054354/https://www.safaribooksonline.com/blog/2013/11/26/image-hashing-with-python/ # noqa: E501\n",
        "\n",
        "\t@image must be a PIL instance.\n",
        "\t@mean how to determine the average luminescence. can try numpy.median instead.\n",
        "\t\"\"\"\n",
        "\tif hash_size < 2:\n",
        "\t\traise ValueError('Hash size must be greater than or equal to 2')\n",
        "\n",
        "\t# reduce size and complexity, then convert to grayscale\n",
        "\timage = image.convert('L').resize((hash_size, hash_size), ANTIALIAS)\n",
        "\n",
        "\t# find average pixel value; 'pixels' is an array of the pixel values, ranging from 0 (black) to 255 (white)\n",
        "\tpixels = numpy.asarray(image)\n",
        "\tavg = mean(pixels)\n",
        "\n",
        "\t# create string of bits\n",
        "\tdiff = pixels > avg\n",
        "\t# make a hash\n",
        "\treturn ImageHash(diff)\n",
        "\n",
        "\n",
        "def phash(image, hash_size=8, highfreq_factor=4):\n",
        "\t# type: (Image.Image, int, int) -> ImageHash\n",
        "\t\"\"\"\n",
        "\tPerceptual Hash computation.\n",
        "\n",
        "\tImplementation follows https://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html\n",
        "\n",
        "\t@image must be a PIL instance.\n",
        "\t\"\"\"\n",
        "\tif hash_size < 2:\n",
        "\t\traise ValueError('Hash size must be greater than or equal to 2')\n",
        "\n",
        "\timport scipy.fftpack\n",
        "\timg_size = hash_size * highfreq_factor\n",
        "\timage = image.convert('L').resize((img_size, img_size), ANTIALIAS)\n",
        "\tpixels = numpy.asarray(image)\n",
        "\tdct = scipy.fftpack.dct(scipy.fftpack.dct(pixels, axis=0), axis=1)\n",
        "\tdctlowfreq = dct[:hash_size, :hash_size]\n",
        "\tmed = numpy.median(dctlowfreq)\n",
        "\tdiff = dctlowfreq > med\n",
        "\treturn ImageHash(diff)\n",
        "\n",
        "\n",
        "def phash_simple(image, hash_size=8, highfreq_factor=4):\n",
        "\t# type: (Image.Image, int, int) -> ImageHash\n",
        "\t\"\"\"\n",
        "\tPerceptual Hash computation.\n",
        "\n",
        "\tImplementation follows https://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html\n",
        "\n",
        "\t@image must be a PIL instance.\n",
        "\t\"\"\"\n",
        "\timport scipy.fftpack\n",
        "\timg_size = hash_size * highfreq_factor\n",
        "\timage = image.convert('L').resize((img_size, img_size), ANTIALIAS)\n",
        "\tpixels = numpy.asarray(image)\n",
        "\tdct = scipy.fftpack.dct(pixels)\n",
        "\tdctlowfreq = dct[:hash_size, 1:hash_size + 1]\n",
        "\tavg = dctlowfreq.mean()\n",
        "\tdiff = dctlowfreq > avg\n",
        "\treturn ImageHash(diff)\n",
        "\n",
        "\n",
        "def dhash(image, hash_size=8):\n",
        "\t# type: (Image.Image, int) -> ImageHash\n",
        "\t\"\"\"\n",
        "\tDifference Hash computation.\n",
        "\n",
        "\tfollowing https://www.hackerfactor.com/blog/index.php?/archives/529-Kind-of-Like-That.html\n",
        "\n",
        "\tcomputes differences horizontally\n",
        "\n",
        "\t@image must be a PIL instance.\n",
        "\t\"\"\"\n",
        "\t# resize(w, h), but numpy.array((h, w))\n",
        "\tif hash_size < 2:\n",
        "\t\traise ValueError('Hash size must be greater than or equal to 2')\n",
        "\n",
        "\timage = image.convert('L').resize((hash_size + 1, hash_size), ANTIALIAS)\n",
        "\tpixels = numpy.asarray(image)\n",
        "\t# compute differences between columns\n",
        "\tdiff = pixels[:, 1:] > pixels[:, :-1]\n",
        "\treturn ImageHash(diff)\n",
        "\n",
        "\n",
        "def dhash_vertical(image, hash_size=8):\n",
        "\t# type: (Image.Image, int) -> ImageHash\n",
        "\t\"\"\"\n",
        "\tDifference Hash computation.\n",
        "\n",
        "\tfollowing https://www.hackerfactor.com/blog/index.php?/archives/529-Kind-of-Like-That.html\n",
        "\n",
        "\tcomputes differences vertically\n",
        "\n",
        "\t@image must be a PIL instance.\n",
        "\t\"\"\"\n",
        "\t# resize(w, h), but numpy.array((h, w))\n",
        "\timage = image.convert('L').resize((hash_size, hash_size + 1), ANTIALIAS)\n",
        "\tpixels = numpy.asarray(image)\n",
        "\t# compute differences between rows\n",
        "\tdiff = pixels[1:, :] > pixels[:-1, :]\n",
        "\treturn ImageHash(diff)\n",
        "\n",
        "\n",
        "def whash(image, hash_size=8, image_scale=None, mode='haar', remove_max_haar_ll=True):\n",
        "\t# type: (Image.Image, int, int | None, WhashMode, bool) -> ImageHash\n",
        "\t\"\"\"\n",
        "\tWavelet Hash computation.\n",
        "\n",
        "\tbased on https://www.kaggle.com/c/avito-duplicate-ads-detection/\n",
        "\n",
        "\t@image must be a PIL instance.\n",
        "\t@hash_size must be a power of 2 and less than @image_scale.\n",
        "\t@image_scale must be power of 2 and less than image size. By default is equal to max\n",
        "\t\t\t\t\tpower of 2 for an input image.\n",
        "\t@mode (see modes in pywt library):\n",
        "\t\t\t\t\t'haar' - Haar wavelets, by default\n",
        "\t\t\t\t\t'db4' - Daubechies wavelets\n",
        "\t@remove_max_haar_ll - remove the lowest low level (LL) frequency using Haar wavelet.\n",
        "\t\"\"\"\n",
        "\timport pywt\n",
        "\tif image_scale is not None:\n",
        "\t\tassert image_scale & (image_scale - 1) == 0, 'image_scale is not power of 2'\n",
        "\telse:\n",
        "\t\timage_natural_scale = 2**int(numpy.log2(min(image.size)))\n",
        "\t\timage_scale = max(image_natural_scale, hash_size)\n",
        "\n",
        "\tll_max_level = int(numpy.log2(image_scale))\n",
        "\n",
        "\tlevel = int(numpy.log2(hash_size))\n",
        "\tassert hash_size & (hash_size - 1) == 0, 'hash_size is not power of 2'\n",
        "\tassert level <= ll_max_level, 'hash_size in a wrong range'\n",
        "\tdwt_level = ll_max_level - level\n",
        "\n",
        "\timage = image.convert('L').resize((image_scale, image_scale), ANTIALIAS)\n",
        "\tpixels = numpy.asarray(image) / 255.\n",
        "\n",
        "\t# Remove low level frequency LL(max_ll) if @remove_max_haar_ll using haar filter\n",
        "\tif remove_max_haar_ll:\n",
        "\t\tcoeffs = pywt.wavedec2(pixels, 'haar', level=ll_max_level)\n",
        "\t\tcoeffs = list(coeffs)\n",
        "\t\tcoeffs[0] *= 0\n",
        "\t\tpixels = pywt.waverec2(coeffs, 'haar')\n",
        "\n",
        "\t# Use LL(K) as freq, where K is log2(@hash_size)\n",
        "\tcoeffs = pywt.wavedec2(pixels, mode, level=dwt_level)\n",
        "\tdwt_low = coeffs[0]\n",
        "\n",
        "\t# Subtract median and compute hash\n",
        "\tmed = numpy.median(dwt_low)\n",
        "\tdiff = dwt_low > med\n",
        "\treturn ImageHash(diff)\n",
        "\n",
        "\n",
        "def colorhash(image, binbits=3):\n",
        "\t# type: (Image.Image, int) -> ImageHash\n",
        "\t\"\"\"\n",
        "\tColor Hash computation.\n",
        "\n",
        "\tComputes fractions of image in intensity, hue and saturation bins:\n",
        "\n",
        "\t* the first binbits encode the black fraction of the image\n",
        "\t* the next binbits encode the gray fraction of the remaining image (low saturation)\n",
        "\t* the next 6*binbits encode the fraction in 6 bins of saturation, for highly saturated parts of the remaining image\n",
        "\t* the next 6*binbits encode the fraction in 6 bins of saturation, for mildly saturated parts of the remaining image\n",
        "\n",
        "\t@binbits number of bits to use to encode each pixel fractions\n",
        "\t\"\"\"\n",
        "\n",
        "\t# bin in hsv space:\n",
        "\tintensity = numpy.asarray(image.convert('L')).flatten()\n",
        "\th, s, v = [numpy.asarray(v).flatten() for v in image.convert('HSV').split()]\n",
        "\t# black bin\n",
        "\tmask_black = intensity < 256 // 8\n",
        "\tfrac_black = mask_black.mean()\n",
        "\t# gray bin (low saturation, but not black)\n",
        "\tmask_gray = s < 256 // 3\n",
        "\tfrac_gray = numpy.logical_and(~mask_black, mask_gray).mean()\n",
        "\t# two color bins (medium and high saturation, not in the two above)\n",
        "\tmask_colors = numpy.logical_and(~mask_black, ~mask_gray)\n",
        "\tmask_faint_colors = numpy.logical_and(mask_colors, s < 256 * 2 // 3)\n",
        "\tmask_bright_colors = numpy.logical_and(mask_colors, s > 256 * 2 // 3)\n",
        "\n",
        "\tc = max(1, mask_colors.sum())\n",
        "\t# in the color bins, make sub-bins by hue\n",
        "\thue_bins = numpy.linspace(0, 255, 6 + 1)\n",
        "\tif mask_faint_colors.any():\n",
        "\t\th_faint_counts, _ = numpy.histogram(h[mask_faint_colors], bins=hue_bins)\n",
        "\telse:\n",
        "\t\th_faint_counts = numpy.zeros(len(hue_bins) - 1)\n",
        "\tif mask_bright_colors.any():\n",
        "\t\th_bright_counts, _ = numpy.histogram(h[mask_bright_colors], bins=hue_bins)\n",
        "\telse:\n",
        "\t\th_bright_counts = numpy.zeros(len(hue_bins) - 1)\n",
        "\n",
        "\t# now we have fractions in each category (6*2 + 2 = 14 bins)\n",
        "\t# convert to hash and discretize:\n",
        "\tmaxvalue = 2**binbits\n",
        "\tvalues = [min(maxvalue - 1, int(frac_black * maxvalue)), min(maxvalue - 1, int(frac_gray * maxvalue))]\n",
        "\tfor counts in list(h_faint_counts) + list(h_bright_counts):\n",
        "\t\tvalues.append(min(maxvalue - 1, int(counts * maxvalue * 1. / c)))\n",
        "\t# print(values)\n",
        "\tbitarray = []\n",
        "\tfor v in values:\n",
        "\t\tbitarray += [v // (2**(binbits - i - 1)) % 2**(binbits - i) > 0 for i in range(binbits)]\n",
        "\treturn ImageHash(numpy.asarray(bitarray).reshape((-1, binbits)))\n",
        "\n",
        "\n",
        "class ImageMultiHash:\n",
        "\t\"\"\"\n",
        "\tThis is an image hash containing a list of individual hashes for segments of the image.\n",
        "\tThe matching logic is implemented as described in Efficient Cropping-Resistant Robust Image Hashing\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(self, hashes):\n",
        "\t\t# type: (list[ImageHash]) -> None\n",
        "\t\tself.segment_hashes = hashes  # type: list[ImageHash]\n",
        "\n",
        "\tdef __eq__(self, other):\n",
        "\t\t# type: (object) -> bool\n",
        "\t\tif other is None:\n",
        "\t\t\treturn False\n",
        "\t\treturn self.matches(other)  # type: ignore\n",
        "\n",
        "\tdef __ne__(self, other):\n",
        "\t\t# type: (object) -> bool\n",
        "\t\treturn not self.matches(other)  # type: ignore\n",
        "\n",
        "\tdef __sub__(self, other, hamming_cutoff=None, bit_error_rate=None):\n",
        "\t\t# type: (ImageMultiHash, float | None, float | None) -> float\n",
        "\t\tmatches, sum_distance = self.hash_diff(other, hamming_cutoff, bit_error_rate)\n",
        "\t\tmax_difference = len(self.segment_hashes)\n",
        "\t\tif matches == 0:\n",
        "\t\t\treturn max_difference\n",
        "\t\tmax_distance = matches * len(self.segment_hashes[0])\n",
        "\t\ttie_breaker = 0 - (float(sum_distance) / max_distance)\n",
        "\t\tmatch_score = matches + tie_breaker\n",
        "\t\treturn max_difference - match_score\n",
        "\n",
        "\tdef __hash__(self):\n",
        "\t\treturn hash(tuple(hash(segment) for segment in self.segment_hashes))\n",
        "\n",
        "\tdef __str__(self):\n",
        "\t\treturn ','.join(str(x) for x in self.segment_hashes)\n",
        "\n",
        "\tdef __repr__(self):\n",
        "\t\treturn repr(self.segment_hashes)\n",
        "\n",
        "\tdef hash_diff(self, other_hash, hamming_cutoff=None, bit_error_rate=None):\n",
        "\t\t# type: (ImageMultiHash, float | None, float | None) -> tuple[int, int]\n",
        "\t\t\"\"\"\n",
        "\t\tGets the difference between two multi-hashes, as a tuple. The first element of the tuple is the number of\n",
        "\t\tmatching segments, and the second element is the sum of the hamming distances of matching hashes.\n",
        "\t\tNOTE: Do not order directly by this tuple, as higher is better for matches, and worse for hamming cutoff.\n",
        "\t\t:param other_hash: The image multi hash to compare against\n",
        "\t\t:param hamming_cutoff: The maximum hamming distance to a region hash in the target hash\n",
        "\t\t:param bit_error_rate: Percentage of bits which can be incorrect, an alternative to the hamming cutoff. The\n",
        "\t\tdefault of 0.25 means that the segment hashes can be up to 25% different\n",
        "\t\t\"\"\"\n",
        "\t\t# Set default hamming cutoff if it's not set.\n",
        "\t\tif hamming_cutoff is None:\n",
        "\t\t\tif bit_error_rate is None:\n",
        "\t\t\t\tbit_error_rate = 0.25\n",
        "\t\t\thamming_cutoff = len(self.segment_hashes[0]) * bit_error_rate\n",
        "\t\t# Get the hash distance for each region hash within cutoff\n",
        "\t\tdistances = []\n",
        "\t\tfor segment_hash in self.segment_hashes:\n",
        "\t\t\tlowest_distance = min(\n",
        "\t\t\t\tsegment_hash - other_segment_hash\n",
        "\t\t\t\tfor other_segment_hash in other_hash.segment_hashes\n",
        "\t\t\t)\n",
        "\t\t\tif lowest_distance > hamming_cutoff:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdistances.append(lowest_distance)\n",
        "\t\treturn len(distances), sum(distances)\n",
        "\n",
        "\tdef matches(self, other_hash, region_cutoff=1, hamming_cutoff=None, bit_error_rate=None):\n",
        "\t\t# type: (ImageMultiHash, int, float | None, float | None) -> bool\n",
        "\t\t\"\"\"\n",
        "\t\tChecks whether this hash matches another crop resistant hash, `other_hash`.\n",
        "\t\t:param other_hash: The image multi hash to compare against\n",
        "\t\t:param region_cutoff: The minimum number of regions which must have a matching hash\n",
        "\t\t:param hamming_cutoff: The maximum hamming distance to a region hash in the target hash\n",
        "\t\t:param bit_error_rate: Percentage of bits which can be incorrect, an alternative to the hamming cutoff. The\n",
        "\t\tdefault of 0.25 means that the segment hashes can be up to 25% different\n",
        "\t\t\"\"\"\n",
        "\t\tmatches, _ = self.hash_diff(other_hash, hamming_cutoff, bit_error_rate)\n",
        "\t\treturn matches >= region_cutoff\n",
        "\n",
        "\tdef best_match(self, other_hashes, hamming_cutoff=None, bit_error_rate=None):\n",
        "\t\t# type: (list[ImageMultiHash], float | None, float | None) -> ImageMultiHash\n",
        "\t\t\"\"\"\n",
        "\t\tReturns the hash in a list which is the best match to the current hash\n",
        "\t\t:param other_hashes: A list of image multi hashes to compare against\n",
        "\t\t:param hamming_cutoff: The maximum hamming distance to a region hash in the target hash\n",
        "\t\t:param bit_error_rate: Percentage of bits which can be incorrect, an alternative to the hamming cutoff.\n",
        "\t\tDefaults to 0.25 if unset, which means the hash can be 25% different\n",
        "\t\t\"\"\"\n",
        "\t\treturn min(\n",
        "\t\t\tother_hashes,\n",
        "\t\t\tkey=lambda other_hash: self.__sub__(other_hash, hamming_cutoff, bit_error_rate)\n",
        "\t\t)\n",
        "\n",
        "\n",
        "def _find_region(remaining_pixels, segmented_pixels):\n",
        "\t\"\"\"\n",
        "\tFinds a region and returns a set of pixel coordinates for it.\n",
        "\t:param remaining_pixels: A numpy bool array, with True meaning the pixels are remaining to segment\n",
        "\t:param segmented_pixels: A set of pixel coordinates which have already been assigned to segment. This will be\n",
        "\tupdated with the new pixels added to the returned segment.\n",
        "\t\"\"\"\n",
        "\tin_region = set()\n",
        "\tnot_in_region = set()\n",
        "\t# Find the first pixel in remaining_pixels with a value of True\n",
        "\tavailable_pixels = numpy.transpose(numpy.nonzero(remaining_pixels))\n",
        "\tstart = tuple(available_pixels[0])\n",
        "\tin_region.add(start)\n",
        "\tnew_pixels = in_region.copy()\n",
        "\twhile True:\n",
        "\t\ttry_next = set()\n",
        "\t\t# Find surrounding pixels\n",
        "\t\tfor pixel in new_pixels:\n",
        "\t\t\tx, y = pixel\n",
        "\t\t\tneighbours = [\n",
        "\t\t\t\t(x - 1, y),\n",
        "\t\t\t\t(x + 1, y),\n",
        "\t\t\t\t(x, y - 1),\n",
        "\t\t\t\t(x, y + 1)\n",
        "\t\t\t]\n",
        "\t\t\ttry_next.update(neighbours)\n",
        "\t\t# Remove pixels we have already seen\n",
        "\t\ttry_next.difference_update(segmented_pixels, not_in_region)\n",
        "\t\t# If there's no more pixels to try, the region is complete\n",
        "\t\tif not try_next:\n",
        "\t\t\tbreak\n",
        "\t\t# Empty new pixels set, so we know whose neighbour's to check next time\n",
        "\t\tnew_pixels = set()\n",
        "\t\t# Check new pixels\n",
        "\t\tfor pixel in try_next:\n",
        "\t\t\tif remaining_pixels[pixel]:\n",
        "\t\t\t\tin_region.add(pixel)\n",
        "\t\t\t\tnew_pixels.add(pixel)\n",
        "\t\t\t\tsegmented_pixels.add(pixel)\n",
        "\t\t\telse:\n",
        "\t\t\t\tnot_in_region.add(pixel)\n",
        "\treturn in_region\n",
        "\n",
        "\n",
        "def _find_all_segments(pixels, segment_threshold, min_segment_size):\n",
        "\t\"\"\"\n",
        "\tFinds all the regions within an image pixel array, and returns a list of the regions.\n",
        "\n",
        "\tNote: Slightly different segmentations are produced when using pillow version 6 vs. >=7, due to a change in\n",
        "\trounding in the greyscale conversion.\n",
        "\t:param pixels: A numpy array of the pixel brightnesses.\n",
        "\t:param segment_threshold: The brightness threshold to use when differentiating between hills and valleys.\n",
        "\t:param min_segment_size: The minimum number of pixels for a segment.\n",
        "\t\"\"\"\n",
        "\timg_width, img_height = pixels.shape\n",
        "\t# threshold pixels\n",
        "\tthreshold_pixels = pixels > segment_threshold\n",
        "\tunassigned_pixels = numpy.full(pixels.shape, True, dtype=bool)\n",
        "\n",
        "\tsegments = []\n",
        "\talready_segmented = set()\n",
        "\n",
        "\t# Add all the pixels around the border outside the image:\n",
        "\talready_segmented.update([(-1, z) for z in range(img_height)])\n",
        "\talready_segmented.update([(z, -1) for z in range(img_width)])\n",
        "\talready_segmented.update([(img_width, z) for z in range(img_height)])\n",
        "\talready_segmented.update([(z, img_height) for z in range(img_width)])\n",
        "\n",
        "\t# Find all the \"hill\" regions\n",
        "\twhile numpy.bitwise_and(threshold_pixels, unassigned_pixels).any():\n",
        "\t\tremaining_pixels = numpy.bitwise_and(threshold_pixels, unassigned_pixels)\n",
        "\t\tsegment = _find_region(remaining_pixels, already_segmented)\n",
        "\t\t# Apply segment\n",
        "\t\tif len(segment) > min_segment_size:\n",
        "\t\t\tsegments.append(segment)\n",
        "\t\tfor pix in segment:\n",
        "\t\t\tunassigned_pixels[pix] = False\n",
        "\n",
        "\t# Invert the threshold matrix, and find \"valleys\"\n",
        "\tthreshold_pixels_i = numpy.invert(threshold_pixels)\n",
        "\twhile len(already_segmented) < img_width * img_height:\n",
        "\t\tremaining_pixels = numpy.bitwise_and(threshold_pixels_i, unassigned_pixels)\n",
        "\t\tsegment = _find_region(remaining_pixels, already_segmented)\n",
        "\t\t# Apply segment\n",
        "\t\tif len(segment) > min_segment_size:\n",
        "\t\t\tsegments.append(segment)\n",
        "\t\tfor pix in segment:\n",
        "\t\t\tunassigned_pixels[pix] = False\n",
        "\n",
        "\treturn segments\n",
        "\n",
        "\n",
        "def crop_resistant_hash(\n",
        "\timage,  # type: Image.Image\n",
        "\thash_func=None,  # type: HashFunc\n",
        "\tlimit_segments=None,  # type: int | None\n",
        "\tsegment_threshold=128,  # type: int\n",
        "\tmin_segment_size=500,  # type: int\n",
        "\tsegmentation_image_size=300  # type: int\n",
        "):\n",
        "\t# type: (...) -> ImageMultiHash\n",
        "\t\"\"\"\n",
        "\tCreates a CropResistantHash object, by the algorithm described in the paper \"Efficient Cropping-Resistant Robust\n",
        "\tImage Hashing\". DOI 10.1109/ARES.2014.85\n",
        "\tThis algorithm partitions the image into bright and dark segments, using a watershed-like algorithm, and then does\n",
        "\tan image hash on each segment. This makes the image much more resistant to cropping than other algorithms, with\n",
        "\tthe paper claiming resistance to up to 50% cropping, while most other algorithms stop at about 5% cropping.\n",
        "\n",
        "\tNote: Slightly different segmentations are produced when using pillow version 6 vs. >=7, due to a change in\n",
        "\trounding in the greyscale conversion. This leads to a slightly different result.\n",
        "\t:param image: The image to hash\n",
        "\t:param hash_func: The hashing function to use\n",
        "\t:param limit_segments: If you have storage requirements, you can limit to hashing only the M largest segments\n",
        "\t:param segment_threshold: Brightness threshold between hills and valleys. This should be static, putting it between\n",
        "\tpeak and through dynamically breaks the matching\n",
        "\t:param min_segment_size: Minimum number of pixels for a hashable segment\n",
        "\t:param segmentation_image_size: Size which the image is resized to before segmentation\n",
        "\t\"\"\"\n",
        "\tif hash_func is None:\n",
        "\t\thash_func = dhash\n",
        "\n",
        "\torig_image = image.copy()\n",
        "\t# Convert to gray scale and resize\n",
        "\timage = image.convert('L').resize((segmentation_image_size, segmentation_image_size), ANTIALIAS)\n",
        "\t# Add filters\n",
        "\timage = image.filter(ImageFilter.GaussianBlur()).filter(ImageFilter.MedianFilter())\n",
        "\tpixels = numpy.array(image).astype(numpy.float32)\n",
        "\n",
        "\tsegments = _find_all_segments(pixels, segment_threshold, min_segment_size)\n",
        "\n",
        "\t# If there are no segments, have 1 segment including the whole image\n",
        "\tif not segments:\n",
        "\t\tfull_image_segment = {(0, 0), (segmentation_image_size - 1, segmentation_image_size - 1)}\n",
        "\t\tsegments.append(full_image_segment)\n",
        "\n",
        "\t# If segment limit is set, discard the smaller segments\n",
        "\tif limit_segments:\n",
        "\t\tsegments = sorted(segments, key=lambda s: len(s), reverse=True)[:limit_segments]\n",
        "\n",
        "\t# Create bounding box for each segment\n",
        "\thashes = []\n",
        "\tfor segment in segments:\n",
        "\t\torig_w, orig_h = orig_image.size\n",
        "\t\tscale_w = float(orig_w) / segmentation_image_size\n",
        "\t\tscale_h = float(orig_h) / segmentation_image_size\n",
        "\t\tmin_y = min(coord[0] for coord in segment) * scale_h\n",
        "\t\tmin_x = min(coord[1] for coord in segment) * scale_w\n",
        "\t\tmax_y = (max(coord[0] for coord in segment) + 1) * scale_h\n",
        "\t\tmax_x = (max(coord[1] for coord in segment) + 1) * scale_w\n",
        "\t\t# Compute robust hash for each bounding box\n",
        "\t\tbounding_box = orig_image.crop((min_x, min_y, max_x, max_y))\n",
        "\t\thashes.append(hash_func(bounding_box))\n",
        "\n",
        "\n",
        "\treturn ImageMultiHash(hashes)"
      ],
      "metadata": {
        "id": "AWsIswOcgrxV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Load and preprocess the image\n",
        "def load_and_preprocess_image(image_path, target_size):\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize(target_size)  # Resize the image to target size\n",
        "    image = np.array(image) / 255.0     # Normalize pixel values to [0, 1]\n",
        "    image = image[np.newaxis, ...]      # Add batch dimension\n",
        "    return image\n",
        "\n",
        "# Define target size for resizing the image\n",
        "target_size = (224, 224)  # Adjust according to your model's input shape\n",
        "\n",
        "# Load and preprocess the image\n",
        "image = load_and_preprocess_image('/content/3_doremon.jpeg', target_size)\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(image)\n",
        "\n",
        "# Convert predictions to desired format\n",
        "object_positions_list = []\n",
        "for j in range(len(predictions)):\n",
        "    object_positions = []\n",
        "    for i in range(0, len(pred), 4):  # Assuming each object has 4 coordinates (a, b, c, d)\n",
        "        if i + 4 <= len(pred):  # Check if there are enough values for unpacking\n",
        "            a, b, c, d = pred[i:i+4]\n",
        "            object_positions.append({j: [[a, b], [c, d]]})\n",
        "        else:\n",
        "            break\n",
        "    object_positions_list += object_positions\n",
        "\n",
        "print(object_positions_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7wHVO02AzO4",
        "outputId": "bfe1f396-e547-4d22-968e-3de00e72df21"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "[{0: [[0.017213995, 0.002100105], [0.0018967421, 0.00093349523]]}, {0: [[0.00041720908, 0.0017323347], [0.0012486514, 0.9723432]]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import imagehash\n",
        "\n",
        "def hash_to_binary(hash_str):\n",
        "    return ''.join(format(ord(char), '08b') for char in hash_str)\n",
        "\n",
        "def embed_hash(image_path, hash_binary, top_left, bottom_right):\n",
        "    image = Image.open(image_path)\n",
        "    pixels = image.load()\n",
        "\n",
        "    # Calculate center point of the bounding box\n",
        "    center_x = (top_left[0] + bottom_right[0]) // 2\n",
        "    center_y = (top_left[1] + bottom_right[1]) // 2\n",
        "\n",
        "    hash_index = 0\n",
        "    for i in range(int(top_left[0]), int(bottom_right[0])):\n",
        "        for j in range(top_left[1], bottom_right[1]):\n",
        "            r, g, b = pixels[i, j]\n",
        "\n",
        "            if hash_index < len(hash_binary):\n",
        "                r = (r & 0xFE) | int(hash_binary[hash_index])\n",
        "                hash_index += 1\n",
        "            if hash_index < len(hash_binary):\n",
        "                g = (g & 0xFE) | int(hash_binary[hash_index])\n",
        "                hash_index += 1\n",
        "            if hash_index < len(hash_binary):\n",
        "                b = (b & 0xFE) | int(hash_binary[hash_index])\n",
        "                hash_index += 1\n",
        "\n",
        "            pixels[i, j] = (r, g, b)\n",
        "\n",
        "    image.save(\"embedded.jpeg\")\n",
        "\n",
        "# Generate hash\n",
        "hash_str = imagehash.average_hash(Image.open('/content/3_doremon.jpeg'))\n",
        "hash_binary = hash_to_binary(str(hash_str))\n",
        "\n",
        "# Define bounding box coordinates (top-left and bottom-right)\n",
        "# Replace these with your object's coordinates\n",
        "for i in object_positions_list:\n",
        "  for j in i.values():\n",
        "    [[a,b],[c,d]]= j\n",
        "top_left = (a, b)   # (x1, y1)\n",
        "bottom_right = (c, d)   # (x2, y2)\n",
        "#print(a,b,c,d)\n",
        "\n",
        "# Embed hash into image at the center of the object\n",
        "embed_hash('embedded.jpeg', hash_binary, top_left, bottom_right)"
      ],
      "metadata": {
        "id": "Fs3meir83oUl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final(image_path):\n",
        "    # Load and preprocess the image\n",
        "    image = load_and_preprocess_image(image_path, (128, 128))\n",
        "\n",
        "    # Predict using the model\n",
        "    predictions = model.predict(image)\n",
        "\n",
        "    # Convert predictions to desired format\n",
        "    object_positions_list = []\n",
        "    for pred in predictions:\n",
        "        object_positions = []\n",
        "        for i in range(0, len(pred), 4):  # Assuming each object has 4 coordinates (a, b, c, d)\n",
        "            if i + 4 <= len(pred):  # Check if there are enough values for unpacking\n",
        "                a, b, c, d = pred[i:i+4]\n",
        "                object_positions.append({'x': [[a, b], [c, d]]})\n",
        "            else:\n",
        "                break\n",
        "        object_positions_list.append({'objects': object_positions})\n",
        "\n",
        "    # Assuming you have these variables defined elsewhere\n",
        "    # Generate hash\n",
        "    hash_str = imagehash.average_hash(Image.open('/content/3_doremon.jpeg'))\n",
        "    hash_binary = hash_to_binary(str(hash_str))\n",
        "    #top_left = top_left   # Top-left coordinate of the object\n",
        "    #bottom_right = bottom_right # Bottom-right coordinate of the object\n",
        "\n",
        "\n",
        "\n",
        "    # Embed hash into the image\n",
        "    embed_hash(image_path, hash_binary, top_left, bottom_right)\n",
        "\n",
        "    # Compute the average hash of the image\n",
        "    otherhash = imagehash.average_hash(Image.open(image_path))\n",
        "    otherhash1 = imagehash.average_hash(Image.open('embedded.jpeg'))\n",
        "\n",
        "    return otherhash, otherhash1\n",
        "\n",
        "otherhash, otherhash1 = final('/content/3_doremon.jpeg')\n",
        "print(otherhash)\n",
        "print(otherhash1)\n",
        "print(otherhash1 == otherhash)\n",
        "print(otherhash1 - otherhash)"
      ],
      "metadata": {
        "id": "_C4exTuy4Ri7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988f2dea-7c0d-4183-c965-d7f8895cf4ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 104ms/step\n",
            "000000ffb7ffff4f\n",
            "000000ffb7ffff4f\n",
            "True\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Provide your ngrok authtoken (replace '<your_auth_token>' with your actual token)\n",
        "ngrok.set_auth_token('2fMDCd00rKWzU0mfFkTbiZBor1J_3PUV9HMREoPU9qRbeStBn')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NTvukA0oOcA",
        "outputId": "7479a8d2-7118-41aa-c792-c90510b7f997"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your Flask app is running on port 5000\n",
        "ngrok_tunnel = ngrok.connect(addr='5000')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fdUX9HRpWst",
        "outputId": "17ac5591-2384-4662-f30a-4d2bfee25279"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-04-20T08:45:38+0000 lvl=warn msg=\"ngrok config file found at both XDG and legacy locations, using XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok_tunnel.public_url\n",
        "print(\"Public URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKFDC5ler3PO",
        "outputId": "43948961-ac1b-47db-eca6-b76cb8e66841"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://1809-34-16-24-115.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install flask pyngrok\n",
        "\n",
        "# from flask import Flask\n",
        "# from pyngrok import ngrok\n",
        "\n",
        "# app = Flask(__name__)\n",
        "\n",
        "# @app.route('/')\n",
        "# def index():\n",
        "#     return 'Hello from Flask!'\n",
        "\n",
        "# # Start ngrok when the app is run\n",
        "# ngrok_tunnel = ngrok.connect(addr='5000')\n",
        "\n",
        "# print(\"Public URL:\", ngrok_tunnel.public_url)\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpSoYxZGVoF4",
        "outputId": "2185a86c-77f7-420f-cd0e-586b327f7a85"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "Public URL: https://4a58-34-16-24-115.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 08:47:37] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 08:47:37] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 08:48:28] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 08:48:29] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "WARNING:pyngrok.process.ngrok:t=2024-04-20T08:53:36+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-ee06e688-34bb-4d9d-a237-990d35fe4867 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-04-20T08:53:36+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-5000-ee06e688-34bb-4d9d-a237-990d35fe4867 err=\"failed to start tunnel: session closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-04-20T08:53:36+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-d1f73f13-56ba-4a15-afea-675e69cb8372 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-04-20T08:53:36+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-5000-d1f73f13-56ba-4a15-afea-675e69cb8372 err=\"failed to start tunnel: session closed\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Flask application\n",
        "from flask import Flask, render_template, request, redirect, url_for\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import imagehash\n",
        "from io import BytesIO\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload():\n",
        "    if 'file' not in request.files:\n",
        "        return redirect(request.url)\n",
        "\n",
        "    file = request.files['file']\n",
        "\n",
        "    if file.filename == '':\n",
        "        return redirect(request.url)\n",
        "\n",
        "    # Read image file\n",
        "    image = Image.open(file)\n",
        "    # Preprocess image\n",
        "    image = image.resize((128, 128))\n",
        "    image = np.array(image)\n",
        "    # Compute image hash\n",
        "    hash_str = imagehash.average_hash(Image.fromarray(image))\n",
        "    hash_binary = hash_str.hash.flatten().tobytes()\n",
        "\n",
        "    # Convert hash to hexadecimal string\n",
        "    hash_hex = hash_str.hex()\n",
        "\n",
        "    # Embed hash into the image\n",
        "    embedded_image = Image.open(BytesIO(file.read()))\n",
        "    embedded_image.save('embedded_image.jpeg')\n",
        "\n",
        "    return render_template('result.html', hash_hex=hash_hex)\n",
        "\n",
        "# Define HTML templates as strings\n",
        "index_html = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Upload Image</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Upload Image</h1>\n",
        "    <form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "        <input type=\"file\" name=\"file\" accept=\"image/*\">\n",
        "        <input type=\"submit\" value=\"Upload\">\n",
        "    </form>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "result_html = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Result</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Image Processing Result</h1>\n",
        "    <p>Hash code: {{ hash_hex }}</p>\n",
        "    <img src=\"/static/embedded_image.jpeg\" alt=\"Embedded Image\">\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Install dependencies\n",
        "!pip install flask pillow\n",
        "\n",
        "# Create HTML template files\n",
        "with open('index.html', 'w') as file:\n",
        "    file.write(index_html)\n",
        "\n",
        "with open('result.html', 'w') as file:\n",
        "    file.write(result_html)\n",
        "\n",
        "# Create directory for static files and an empty image file\n",
        "!mkdir static\n",
        "!touch static/embedded_image.jpeg\n",
        "\n",
        "# Start ngrok when the app is run\n",
        "run_with_ngrok(app)\n",
        "app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_9snZNoti4R",
        "outputId": "61b46130-5f5f-4e25-d79a-e51df2f62bde"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "mkdir: cannot create directory ‘static’: File exists\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "Exception in thread Thread-10:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 203, in _new_conn\n",
            "    sock = connection.create_connection(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 791, in urlopen\n",
            "    response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 497, in _make_request\n",
            "    conn.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 395, in request\n",
            "    self.endheaders()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 243, in connect\n",
            "    self.sock = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 218, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7e8424169ba0>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 486, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 845, in urlopen\n",
            "    retries = retries.increment(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\", line 515, in increment\n",
            "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7e8424169ba0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1378, in run\n",
            "    self.function(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask_ngrok.py\", line 70, in start_ngrok\n",
            "    ngrok_address = _run_ngrok()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask_ngrok.py\", line 35, in _run_ngrok\n",
            "    tunnel_url = requests.get(localhost_url).text  # Get the tunnel information\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 73, in get\n",
            "    return request(\"get\", url, params=params, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 59, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 519, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7e8424169ba0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Flask application\n",
        "from flask import Flask, render_template, request, redirect\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import imagehash\n",
        "from io import BytesIO\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload():\n",
        "    if 'file' not in request.files:\n",
        "        return redirect(request.url)\n",
        "\n",
        "    file = request.files['file']\n",
        "\n",
        "    if file.filename == '':\n",
        "        return redirect(request.url)\n",
        "\n",
        "    # Read image file\n",
        "    image = Image.open(file)\n",
        "    # Preprocess image\n",
        "    image = image.resize((128, 128))\n",
        "    image = np.array(image)\n",
        "    # Compute image hash\n",
        "    hash_str = imagehash.average_hash(Image.fromarray(image))\n",
        "    hash_hex = hash_str.hex()\n",
        "\n",
        "    # Embed hash into the image\n",
        "    embedded_image = Image.open(BytesIO(file.read()))\n",
        "    embedded_image.save('static/embedded_image.jpeg')\n",
        "\n",
        "    return render_template('result.html', hash_hex=hash_hex)\n",
        "\n",
        "# Install dependencies\n",
        "!pip install flask pillow pyngrok\n",
        "\n",
        "# Define HTML templates as strings\n",
        "index_html = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Upload Image</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Upload Image</h1>\n",
        "    <form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "        <input type=\"file\" name=\"file\" accept=\"image/*\">\n",
        "        <input type=\"submit\" value=\"Upload\">\n",
        "    </form>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "result_html = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Result</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Image Processing Result</h1>\n",
        "    <p>Hash code: {{ hash_hex }}</p>\n",
        "    <img src=\"/static/embedded_image.jpeg\" alt=\"Embedded Image\">\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Create templates directory if it doesn't exist\n",
        "if not os.path.exists('templates'):\n",
        "    os.makedirs('templates')\n",
        "\n",
        "# Create HTML template files\n",
        "with open('templates/index.html', 'w') as file:\n",
        "    file.write(index_html)\n",
        "\n",
        "with open('templates/result.html', 'w') as file:\n",
        "    file.write(result_html)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(addr='5000', proto='http')\n",
        "print('Public URL:', public_url)\n",
        "\n",
        "# Run Flask app\n",
        "app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbxXuQWHtveL",
        "outputId": "19b38e4f-3771-45f4-e0ee-d8ebe70b3fa3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "Public URL: NgrokTunnel: \"https://6725-34-16-24-115.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:04:18] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:04:19] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "ERROR:__main__:Exception on /upload [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 2529, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1825, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1799, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
            "  File \"<ipython-input-4-5da4ff0bdeda>\", line 33, in upload\n",
            "    hash_hex = hash_str.hex()\n",
            "AttributeError: 'ImageHash' object has no attribute 'hex'\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:04:31] \"\u001b[35m\u001b[1mPOST /upload HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Flask application\n",
        "from flask import Flask, render_template, request, redirect\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import imagehash\n",
        "from io import BytesIO\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload():\n",
        "    try:\n",
        "        if 'file' not in request.files:\n",
        "            return \"No file uploaded\", 400\n",
        "\n",
        "        file = request.files['file']\n",
        "\n",
        "        if file.filename == '':\n",
        "            return \"No file selected\", 400\n",
        "\n",
        "        # Read image file\n",
        "        image = Image.open(file)\n",
        "        # Preprocess image\n",
        "        image = image.resize((128, 128))\n",
        "        image = np.array(image)\n",
        "        # Compute image hash\n",
        "        hash_str = imagehash.average_hash(Image.fromarray(image))\n",
        "        hash_hex = hash_str.hex()\n",
        "\n",
        "        # Embed hash into the image\n",
        "        embedded_image = Image.open(BytesIO(file.read()))\n",
        "        embedded_image.save('static/embedded_image.jpeg')\n",
        "\n",
        "        return render_template('result.html', hash_hex=hash_hex)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\", 500\n",
        "\n",
        "# Install dependencies\n",
        "!pip install flask pillow pyngrok\n",
        "\n",
        "# Define HTML templates as strings\n",
        "index_html = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Upload Image</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Upload Image</h1>\n",
        "    <form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "        <input type=\"file\" name=\"file\" accept=\"image/*\">\n",
        "        <input type=\"submit\" value=\"Upload\">\n",
        "    </form>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "result_html = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Result</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Image Processing Result</h1>\n",
        "    <p>Hash code: {{ hash_hex }}</p>\n",
        "    <img src=\"/static/embedded_image.jpeg\" alt=\"Embedded Image\">\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Create templates directory if it doesn't exist\n",
        "if not os.path.exists('templates'):\n",
        "    os.makedirs('templates')\n",
        "\n",
        "# Create HTML template files\n",
        "with open('templates/index.html', 'w') as file:\n",
        "    file.write(index_html)\n",
        "\n",
        "with open('templates/result.html', 'w') as file:\n",
        "    file.write(result_html)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(addr='5000', proto='http')\n",
        "print('Public URL:', public_url)\n",
        "\n",
        "# Run Flask app\n",
        "app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVuIEr_qwcIi",
        "outputId": "7b1c387a-ae73-49c4-87a1-e40f9eb32d0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-04-20T09:06:44+0000 lvl=warn msg=\"ngrok config file found at both XDG and legacy locations, using XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://3eb4-34-16-24-115.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:06:53] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:06:53] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:07:00] \"\u001b[35m\u001b[1mPOST /upload HTTP/1.1\u001b[0m\" 500 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:07:46] \"\u001b[35m\u001b[1mPOST /upload HTTP/1.1\u001b[0m\" 500 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:07:52] \"\u001b[35m\u001b[1mPOST /upload HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Flask application\n",
        "from flask import Flask, render_template, request, send_file\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import imagehash\n",
        "from io import BytesIO\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload():\n",
        "    try:\n",
        "        if 'file' not in request.files:\n",
        "            return \"No file uploaded\", 400\n",
        "\n",
        "        file = request.files['file']\n",
        "\n",
        "        if file.filename == '':\n",
        "            return \"No file selected\", 400\n",
        "\n",
        "        # Read image file\n",
        "        image = Image.open(file.stream)\n",
        "        # Preprocess image\n",
        "        image = image.resize((128, 128))\n",
        "        # Compute image hash\n",
        "        hash_str = imagehash.average_hash(image)\n",
        "        hash_hex = str(hash_str)\n",
        "\n",
        "        # Embed hash into the image filename\n",
        "        filename = f'static/embedded_image_{hash_hex}.jpeg'\n",
        "        # Save the original image with the embedded hash in the filename\n",
        "        image.save(filename)\n",
        "\n",
        "        return render_template('result.html', hash_hex=hash_hex, filename=filename)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\", 500\n",
        "\n",
        "\n",
        "# Define HTML templates as strings\n",
        "index_html = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Upload Image</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Upload Image</h1>\n",
        "    <form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "        <input type=\"file\" name=\"file\" accept=\"image/*\">\n",
        "        <input type=\"submit\" value=\"Upload\">\n",
        "    </form>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "result_html = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Result</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Image Processing Result</h1>\n",
        "    <p>Hash code: {{ hash_hex }}</p>\n",
        "    <img src=\"{{ filename }}\" alt=\"Embedded Image\">\n",
        "    <p><a href=\"{{ filename }}\" download>Download Embedded Image</a></p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Create templates directory if it doesn't exist\n",
        "if not os.path.exists('templates'):\n",
        "    os.makedirs('templates')\n",
        "\n",
        "# Create HTML template files\n",
        "with open('templates/index.html', 'w') as file:\n",
        "    file.write(index_html)\n",
        "\n",
        "with open('templates/result.html', 'w') as file:\n",
        "    file.write(result_html)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(addr='5000', proto='http')\n",
        "print('Public URL:', public_url)\n",
        "\n",
        "# Run Flask app\n",
        "app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3vbsjqxw79A",
        "outputId": "cd5b51ab-36ad-4655-c444-a575104958b1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-04-20T09:30:10+0000 lvl=warn msg=\"ngrok config file found at both XDG and legacy locations, using XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://1804-34-16-24-115.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:30:22] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:30:22] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:30:29] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:30:29] \"GET /static/embedded_image_000000ffb7ffff4f.jpeg HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 09:30:54] \"GET /static/embedded_image_000000ffb7ffff4f.jpeg HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}